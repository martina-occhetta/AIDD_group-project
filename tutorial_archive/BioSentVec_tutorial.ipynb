{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioSentVec Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides a fundemental introduction to our BioSentVec models. It illustrates (1) how to load the model, (2) an example function to preprocess sentences, (3) an example application that uses the model and (4) further resources for using the model more broadly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download BioSentVec model and install all the related python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sent2vec\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load BioSentVec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please specify the location of the BioSentVec model to model_path. It may take a while to load the model at the first time. Pre-trained model can be found here: https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/BioSentVec_PubMed_MIMICIII-bigram_d700.bin. For information on installing sent2vec, refer to following readme: https://github.com/epfml/sent2vec/tree/master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /data/home/bty381/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /data/home/bty381/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'BioSentVec_PubMed_MIMICIII-bigram_d700.bin'\n",
    "model = sent2vec.Sent2vecModel()\n",
    "try:\n",
    "    model.load_model(model_path)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print('model successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no one-size-fits-all solution to preprocess sentences. We demonstrate a representative code example as below. This is also consistent with the preprocessing appaorach when we trained BioSentVec models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_sentence(text):\n",
    "    text = text.replace('/', ' / ')\n",
    "    text = text.replace('.-', ' .- ')\n",
    "    text = text.replace('.', ' . ')\n",
    "    text = text.replace('\\'', ' \\' ')\n",
    "    text = text.replace(';', ' ; ')\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = [token for token in word_tokenize(text) if token not in punctuation and token not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using the preprocess_sentence function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = preprocess_sentence('Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.')\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retrieve a sentence vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a sentence is preprocessed, we can pass it to the BioSentVec model to retrieve a vector representation of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vector = model.embed_sentence(sentence)\n",
    "print(sentence_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also use embed_sentences to retrieve vector representations of multiple sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the vector representation depends on the dimension parameter. In this case, we set the dimension to 700: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute sentence similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we demonstrate how to compute the sentence similarity between a sentence pair using the BioSentVec model. We firstly use the above code examples to get vector representations of sentences. Then we compute the cosine similarity between the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vector1 = np.squeeze(model.embed_sentence(preprocess_sentence('In vitro anticancer activity against 2 NCI SCLC cell lines; inactive')), axis=0)\n",
    "sentence_vector2 = np.squeeze(model.embed_sentence(preprocess_sentence('In vitro anticancer activity against 11 NCI NSCLC cell lines; inactive')), axis=0)\n",
    "sentence_vector3 = np.squeeze(model.embed_sentence(preprocess_sentence('In vitro anticancer activity against 6 NCI ovarian cancer cell lines; inactive')), axis=0)\n",
    "\n",
    "cosine_sim = 1 - distance.cosine(sentence_vector1, sentence_vector2)\n",
    "print('cosine similarity:', cosine_sim)\n",
    "cosine_sim = 1 - distance.cosine(sentence_vector1, sentence_vector3)\n",
    "print('cosine similarity:', cosine_sim)\n",
    "cosine_sim = 1 - distance.cosine(sentence_vector3, sentence_vector2)\n",
    "print('cosine similarity:', cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to compute embeddings for assay descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data.csv')\n",
    "# Define a function to compute embeddings\n",
    "def compute_embeddings(row):\n",
    "    text = row['description']\n",
    "    embedding = np.squeeze(model.embed_sentence(preprocess_sentence(text)), axis=0)\n",
    "    return embedding\n",
    "\n",
    "# Apply the function to each row and create a new 'embeddings' column\n",
    "df['embeddings'] = df.apply(compute_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('assays_with_embeddings.csv')\n",
    "#test = pd.read_csv('assays_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example for a pair that is relatively less similar.\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input vector should be 1-D.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sentence_vector3 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39membed_sentence(preprocess_sentence(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFurthermore, increased CREB expression in breast tumors is associated with poor prognosis, shorter survival and higher risk of metastasis.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m cosine_sim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mdistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_vector3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine similarity:\u001b[39m\u001b[38;5;124m'\u001b[39m, cosine_sim)\n",
      "File \u001b[0;32m~/.conda/envs/BioBert/lib/python3.8/site-packages/scipy/spatial/distance.py:670\u001b[0m, in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m \n\u001b[1;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# clamp the result to 0-2\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;241m2.0\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/BioBert/lib/python3.8/site-packages/scipy/spatial/distance.py:610\u001b[0m, in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrelation\u001b[39m(u, v, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, centered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    578\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    Compute the correlation distance between two 1-D arrays.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m     v \u001b[38;5;241m=\u001b[39m _validate_vector(v)\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/BioBert/lib/python3.8/site-packages/scipy/spatial/distance.py:302\u001b[0m, in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput vector should be 1-D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Input vector should be 1-D."
     ]
    }
   ],
   "source": [
    "sentence_vector3 = model.embed_sentence(preprocess_sentence('Furthermore, increased CREB expression in breast tumors is associated with poor prognosis, shorter survival and higher risk of metastasis.'))\n",
    "cosine_sim = 1 - distance.cosine(sentence_vector, sentence_vector3)\n",
    "print('cosine similarity:', cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. More resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example demonstrates an unsupervised way to use the BioSentVec model. In addition, we summarize a few useful resources:\n",
    "\n",
    "#### (1) The Sent2vec homepage (https://github.com/epfml/sent2vec) has a few pre-trained sentence embeddings from general English copora. \n",
    "#### (2) You can also develop deep learning models to learn sentence similarity in a supervised manner.\n",
    "#### (3) You can also use the BioSentVec in other applications, such as multi-label classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using some of our pre-trained models for your application, please cite the following paper:\n",
    "\n",
    "Chen Q, Peng Y, Lu Z. BioSentVec: creating sentence embeddings for biomedical texts. 2018. arXiv:1810.09302."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioBert",
   "language": "python",
   "name": "biobert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
